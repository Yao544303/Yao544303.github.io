<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  




<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="喵十八の小窝">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="喵十八の小窝">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="喵十八の小窝">
<meta name="twitter:description">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>

  <title> 喵十八の小窝 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">喵十八の小窝</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th fa-fw"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-heartbeat fa-fw"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/27/percentrank/" itemprop="url">
                  Spark 爬坑记录之percent_rank()
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-27T23:14:20+08:00" content="2017-12-27">
              2017-12-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在Kmeans 预处理之前的数据预处理部分，需要做一次类似percent_rank() 操作。<br>举个例子，输入一条记录为user_1,key1,value_1<br>输入多条记录<br>按照key1 聚合之后，结果为key1,list[value1,value2…..]<br>将list 排序，并获取count  结果为    key1，count，list<br>然后计算user1 这条记录的rank  =  index（value1）/count</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    val ah_freqlist_dic_old = user_ah_freq_dic.map(x=&gt;(x._1._2,Nil:+x._2))</span><br><span class="line">      .reduceByKey(_:::_)</span><br><span class="line">      .map(x=&gt;(x._1,(x._2.length).toString +: x._2.sorted))</span><br><span class="line">      .collectAsMap()</span><br><span class="line">val ah_freqlist_dic = sc.broadcast(ah_freqlist_dic_old)</span><br><span class="line">val user_ah_percent_dic = user_ah_freq_dic.map(t=&gt;((t._1._1,t._1._2),ah_freqlist_dic.value.getOrElse(t._1._2,Nil).indexOf(t._2)/((ah_freqlist_dic.value.getOrElse(t._1._2,Nil)(0).toInt).toFloat)))</span><br></pre></td></tr></table></figure>
<p>上述代码在实现的时候效率极低。</p>
<p>当把这段代码换成 percent_rank() 之后，奇迹发生了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val df = sqlContext.createDataFrame(user_ah_freq_dic).toDF(&quot;user&quot;,&quot;ah&quot;,&quot;freq&quot;)</span><br><span class="line">   df.registerTempTable(&quot;uahf&quot;)</span><br><span class="line">   val sql=&quot;select user,ah,percent_rank() over (partition by ah order by freq) as rank from uahf&quot;</span><br><span class="line"></span><br><span class="line">   val user_ah_percent_dic = sqlContext.sql(sql).rdd.map(x=&gt;((x(0).toString,x(1).toString),x(2).toString.toFloat))</span><br></pre></td></tr></table></figure></p>
<p>果然spark sql 的是做了优化的。阅读spark sql 的源码，又有计划了</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/27/scala版本冲突/" itemprop="url">
                  Spark 爬坑记录之开发Scala版本冲突
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-27T23:14:09+08:00" content="2017-12-27">
              2017-12-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>若在maven 中配置了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line"> &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;</span><br><span class="line"> &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;</span><br><span class="line"> &lt;executions&gt;</span><br><span class="line"> &lt;execution&gt;</span><br><span class="line"> &lt;goals&gt;</span><br><span class="line"> &lt;goal&gt;compile&lt;/goal&gt;</span><br><span class="line"> &lt;goal&gt;testCompile&lt;/goal&gt;</span><br><span class="line"> &lt;/goals&gt;</span><br><span class="line"> &lt;/execution&gt;</span><br><span class="line"> &lt;/executions&gt;</span><br><span class="line"> &lt;configuration&gt;</span><br><span class="line"> &lt;scalaVersion&gt;$&#123;scala.version&#125;.6&lt;/scalaVersion&gt;</span><br><span class="line"> &lt;args&gt;</span><br><span class="line"> &lt;arg&gt;-target:jvm-1.7&lt;/arg&gt;</span><br><span class="line"> &lt;/args&gt;</span><br><span class="line"> &lt;/configuration&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure></p>
<p>无需再在IDEA中配置 scala 的sdk 版本不一致会冲突</p>
<p>注意这一行，最好标注小版本 2.10.6</p>
<scalaversion>2.10.6</scalaversion>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/27/spark2-x迁移至1-6/" itemprop="url">
                  将基于Spark 2.x 开发的LDA 程序 迁移至Spark 1.6 的环境
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-27T23:10:50+08:00" content="2017-12-27">
              2017-12-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>对方提供的LDA 聚类程序，是基于Spark 2.x 的，但是，我们的生产环境是Spark 1.6。 恩那么问题就来了，怎么让基于Spark 2.x 的代码在Spark 1.6 上跑起来。第一个想法是，只要把SparkSession 改为SparkContext 和 SQLContext 就行了。然后发现自己真的图样图森破。对方非常高端的使用了ml库，当然这不是问题。对方是用python 写的，当然这也不是问题<del>毕竟小学生都要学python了，作为一个程序员不会python 就说不过去了</del>对方的python 版本是2.7，当然这更不是问题。但是当你遇到需要将python 2.7 写的基于Spark 2.x  ml 写的代码迁移到spark 1.6 上的时候，就有问题了。<br><del>他喵的，老子都要精分了，一直在python 2.7 python 3.0  spark 1.6  spark2.2 版本间切换，在java，scala ，python 语言间切换</del></p>
<h1 id="改造经过"><a href="#改造经过" class="headerlink" title="改造经过"></a>改造经过</h1><p>任务到手，谋定后动，当然先开始分析。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder.master(&apos;yarn&apos;) \</span><br><span class="line">	.appName(&apos;marketing_data_lda_clustering&apos;) \</span><br><span class="line">	.enableHiveSupport() \</span><br><span class="line">	.getOrCreate()</span><br></pre></td></tr></table></figure></p>
<p>这个，当然小case啦。改成sparkContext 就行了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf().setMaster(&apos;yarn&apos;) \</span><br><span class="line">	.setAppName(&apos;marketing_data_lda_clustering&apos;) </span><br><span class="line">sc = SparkContext(conf = conf)	</span><br><span class="line">sqlContext = SQLContext(sc)</span><br></pre></td></tr></table></figure></p>
<p>然后，以为就搞定了，开开心心的spark-submit。不出意外的报错，提示下面代码缺少方法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lda = LDA(k=30, seed=long(time.time()), optimizer=&quot;em&quot;)</span><br><span class="line">model = lda.fit(feature_dataframe)</span><br></pre></td></tr></table></figure></p>
<p>怎么可能！！！ ml 怎么可能没有fit？？？<br>带着满腔疑惑，打开了api，然后发现，不是ml 没有fit，是1.6 的ml 库中压根就没有LDA！！！<br>哦对，顺便看了眼隔壁Scala 的API 两个都有。。。<br><del>心情复杂</del><br>看来只能将ml 的程序改成mllib了<del>毕竟我当年也改过，只不过是java 的而已</del><br>说干就干，首先将fit 改为train，然后将输入从dataframe 改为RDD 即可。因为构建features的时候，对方已经将df 转为了rdd，只需要将对方从rdd转为df 的那一步去掉就行了。<del>简直完美</del><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">features = data.rdd.map(lambda x: (x[0], x[1:])).groupByKey().mapValues(list).map(lambda row: build_sparse_vector(row, tag_index_map)).cache()</span><br><span class="line">model = LDA.train(rdd, k=10, seed=1)</span><br></pre></td></tr></table></figure></p>
<p>然后，不出意外的报错了，类型不匹配。<br>怎么会类型不匹配呢？一定是我对LDA 的算法理解不够深入。干脆找个简单的例子来测试下吧。<br>于是照着example 撸了下面的代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf().setMaster(&apos;local&apos;).setAppName(&apos;marketing_data_lda_clustering&apos;) </span><br><span class="line">sc = SparkContext(conf = conf)	</span><br><span class="line">sqlContext = SQLContext(sc)</span><br><span class="line">data = [</span><br><span class="line">     [1, Vectors.dense([0.0, 1.0])],</span><br><span class="line">     [2, SparseVector(2, &#123;0: 1.0&#125;)],</span><br><span class="line">]</span><br><span class="line">rdd =  sc.parallelize(data)</span><br><span class="line">model = LDA.train(rdd, k=2, seed=1)</span><br><span class="line">print(model.vocabSize())</span><br><span class="line"></span><br><span class="line">print(model.describeTopics())</span><br><span class="line">print(model.describeTopics(1))</span><br></pre></td></tr></table></figure></p>
<p>结果一次通过，正确无比。那么问题究竟出在哪里呢？ 算法的各项参数差异不大，应该不会出问题。有问题的就只能是rdd了。python 新学，不会debug，只能祭出print 大法了<del>顺便吐槽下，能让服务器版本2.7  driver python 版本2.6 的 也是醉了</del><br>将测试用的rdd collect 然后打印出来的结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[1, DenseVector([0.0, 1.0])], [2, SparseVector(2, &#123;0: 1.0&#125;)]]</span><br></pre></td></tr></table></figure></p>
<p>有问题的代码打出来是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(u&apos;D5A55D4E4E8F484FB4ACFCCAE1E37BFE&apos;, SparseVector(10, &#123;1: 1.0, 7: 1.0&#125;)), (u&apos;41AF98FE050658F50F0DD55F823CE954&apos;, SparseVector(10, &#123;2: 1.0, 4: 1.0&#125;)), (u&apos;4CD09883D04D35697666115ADE9393DC&apos;, SparseVector(10, &#123;5: 1.0, 6: 1.0, 8: 1.0, 9: 1.0&#125;)), (u&apos;CF5F565193E6FE9B5D7D50F3DADCB85F&apos;, SparseVector(10, &#123;3: 1.0&#125;)), (u&apos;E776CC8BAF4900C092D9789077EF1E56&apos;, SparseVector(10, &#123;0: 1.0&#125;))]</span><br></pre></td></tr></table></figure></p>
<p>这他妈坑爹呢！！！ 对方的构造方法返回居然是这个格式，无奈在features 加上如下的map 方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.map(lambda x: [x[0], x[1]])</span><br></pre></td></tr></table></figure></p>
<p>然而报错依赖。绝望之际，只能去读源码了。以前一直读的是scala，不知道python的源码会怎们样？<br>怀着激动的心情，我打开了spark源码。<br>机智如我，一下子就找到了python\pyspark\mllib 路径下的clustering.py文件<del>这不是废话么</del><br>找到了LDA的实现<br>关键的实现，就这么一句<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = callMLlibFunc(&quot;trainLDAModel&quot;, rdd, k, maxIterations,</span><br><span class="line">                      docConcentration, topicConcentration, seed,</span><br><span class="line">                      checkpointInterval, optimizer)</span><br></pre></td></tr></table></figure></p>
<p>这个callMLlibFunc 方法好厉害，看了好几个方法都是调用这个。于是就追到这个方法里看了下。<br>结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def callJavaFunc(sc, func, *args):</span><br><span class="line">    &quot;&quot;&quot; Call Java Function &quot;&quot;&quot;</span><br><span class="line">    args = [_py2java(sc, a) for a in args]</span><br><span class="line">    return _java2py(sc, func(*args))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def callMLlibFunc(name, *args):</span><br><span class="line">    &quot;&quot;&quot; Call API in PythonMLLibAPI &quot;&quot;&quot;</span><br><span class="line">    sc = SparkContext.getOrCreate()</span><br><span class="line">    api = getattr(sc._jvm.PythonMLLibAPI(), name)</span><br><span class="line">    return callJavaFunc(sc, api, *args)</span><br></pre></td></tr></table></figure></p>
<p>他喵的，原来pyspark mllib 的底层实现是调了jar 。真是简洁的设计呢。</p>
<p>原来python并不是实现。。正当绝望之时，想起当时调试LR，被labeledpoint 支配的恐惧。难道id 输入不能是string？和graphx 一样都必须转化为long？python既然依赖于scala 的源码，那查scala 的源码岂不是一样？<br>于是查啊查，查到LDA 的scala 执行<br>在org.apache.spark.mllib.clustering.LDA.scala  中查到有个run<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def run(documents: JavaPairRDD[java.lang.Long, Vector]): LDAModel = &#123;</span><br><span class="line">  run(documents.rdd.asInstanceOf[RDD[(Long, Vector)]])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>好了很明确了，就是要转成long，那df 为什么不用转呢？</p>
<p>又开始查ml的源码</p>
<p> 在fit 方法中，有这么一段<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val oldData = LDA.getOldDataset(dataset, $(featuresCol))</span><br></pre></td></tr></table></figure></p>
<p>我能吐槽么。。。 老版本的能用的，直接加个前缀。。。。。。<br>然后再跟到vgetOldDataset<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/** Get dataset for spark.mllib LDA */</span><br><span class="line">private[clustering] def getOldDataset(</span><br><span class="line">     dataset: Dataset[_],</span><br><span class="line">     featuresCol: String): RDD[(Long, OldVector)] = &#123;</span><br><span class="line">  dataset</span><br><span class="line">    .withColumn(&quot;docId&quot;, monotonically_increasing_id())</span><br><span class="line">    .select(&quot;docId&quot;, featuresCol)</span><br><span class="line">    .rdd</span><br><span class="line">    .map &#123; case Row(docId: Long, features: Vector) =&gt;</span><br><span class="line">      (docId, OldVectors.fromML(features))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>连带着注释一起贴了，说好的ml 是对df 有了优化的呢，他喵的，这不是 还是转成mllib 实现了么！！！<br>所以，问题其实已经解决了，就是这一句<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">withColumn(&quot;docId&quot;, monotonically_increasing_id())</span><br></pre></td></tr></table></figure></p>
<p>生成了一个long 类型的id。<br>ok 完美落幕，再一次愉快的submit。<br>然后 WTF！！！！！  又他娘的报错。<br>从describeTopics的结果生成df 的时候发错，然后发现。<br>RDD  describeTopics的结果是这样的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[([7, 8, 1, 0, 4, 3, 2, 6, 9, 5], [0.10368743342260674, 0.10207234154290727, 0.10138905514695376, 0.10061123338885637, 0.09970383057872025, 0.09948034467474759, 0.09945100732346705, 0.09850959571098065, 0.09837913555700037, 0.09671602265375995]), ([5, 9, 6, 2, 3, 4, 0, 1, 8, 7], [0.10328397706229461, 0.10162086430285339, 0.1014904041601532, 0.10054899262906491, 0.100519655280321, 0.10029616939567182, 0.09938876666399324, 0.09861094497314936, 0.09792765863627545, 0.09631256689622307])]</span><br></pre></td></tr></table></figure></p>
<p>DF describeTopics 的结果在前面有个编号。是ML 在调用时有入参，做了一次累加。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def describeTopics(maxTermsPerTopic: Int)</span><br></pre></td></tr></table></figure></p>
<p>so 略作调整，通过row number 加了个字段搞定。至此 告一段路</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/27/数据挖掘/" itemprop="url">
                  数据挖掘 & Spark MLlib 经验记录
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-27T23:06:33+08:00" content="2017-12-27">
              2017-12-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <pre><code>之前断断续续，用Spark MLlib 做了将近两个月的数据挖掘，记录点东西。
</code></pre><p>1.数据挖掘是有目的的，Spark只是工具<br>在数据挖掘操作前，需要明确，通过这些计算，你希望从这一堆数据中获取到什么。不然只是每个算法跑一遍，也只能证明你调用Spark API 的能力合格了。</p>
<p> 在最开始的时候，进入了一个误区，以为社区炒的火热的Spark是全知全能的。数据挖掘什么的，Spark就能搞定了。然而，Spark毕竟只是一个工具，使用工具归根结底还是人。最开始，只是想掌握Spark这种技术而已，从而忽视了数据挖掘的目的（当然，这也和团队构成有关，一个产品经理加我一个研发，总觉得和业务相关的事由产品经理去实现就行。。。 图样图森破啊 ）</p>
<p>将Spark MLlib 中的算法能跑的都跑了一遍，得到了许多自己根本不知道意义的数据，才发现，其实做了无用功。</p>
<p>2.数据可视化很重要<br>看到这个需求的时候，第一反应是找相应的工具。的确有很多数据可视化的工具，画出来的图非常炫。但是，这些工具大部分真的只是画图的工具，需要你将数据整理好输入进去，然后展现出来。然而我需要的则是能够做一些简单汇总计算的操作。于是试过了echarts 、plotyly.js 、R 等等，居然发现是Excel 用的最顺手。然而Excel 却难以处理如此庞大的数据只能进行切割。下一步是该好好学学python了，考虑直接用python on Spark 进行计算，然后对结果画图，这样应该会简单很多。</p>
<p>3.不要随便造轮子<br>用Spark用了几天，然后被zb推荐用了weka，方才恍然，TMD世界上怎么有真么方便的工具啊，还要Spark MLlib 干蛋啊。各种算法都整合好，数据处理又方便，还能出简单的图，简直完美。</p>
<p>4.知己知彼<br>接上，既然weka这么完美，那为何还要用Spark呢？归根结底，还是数据量太大，只能使用Spark。这也是Spark的优势所在。即便这个玩意，对机器配置要求高，容易OOM，GC一团乱码，还不稳定。然而做离线的机器学习处理，以上这些劣势who care？只要它够快，处理的数据够大，能出结果就行了。没有工具是万能的，只要他能满足你的需求他就是个好工具。</p>
<p>5.MLlib VS ML<br>诚然，一开始想上ML的。封装程度更高的API，简洁的Pipeline，一切都是那么美好。然而数据却不是那么美好。很多源数据的清洗没法用SparkSQL 或者 Hive进行。（好吧 我承认我很水，SQL 只是刚会用而已）于是采用了MLlib。</p>
<p>因为数据是存在Hive表里的，思路就如下：</p>
<p>SparkSQL 取数据 -&gt;RDD  （进行清洗）-&gt;MLlib （进行挖掘） -&gt;python (可视化）</p>
<p>6.讲故事很重要<br>说实话，最后计算出来的数据，其实我是看不懂的，还好zb厉害，能够给出各种合理的解释，然后按照相应的方向进行深挖。</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/27/spark开发环境搭建/" itemprop="url">
                  spark开发环境搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-27T23:03:36+08:00" content="2017-12-27">
              2017-12-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Spark本地安装"><a href="#Spark本地安装" class="headerlink" title="Spark本地安装"></a>Spark本地安装</h1><ul>
<li>Java 安装</li>
<li>Spark 安装</li>
<li>PySpark 安装</li>
</ul>
<h2 id="Java安装"><a href="#Java安装" class="headerlink" title="Java安装"></a>Java安装</h2><p>这一部分不多赘述，配置好Java 环境变量即可。</p>
<h2 id="Spark-安装"><a href="#Spark-安装" class="headerlink" title="Spark 安装"></a>Spark 安装</h2><p>在<a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">官网</a>下载所需版本的Spark 压缩包</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3698622-0b4a4a91b763512a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>解压至对应目录，如 C:\dev\spark1.6.3<br>配置环境变量<br><img src="http://upload-images.jianshu.io/upload_images/3698622-fe96697c1ec0e859.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这时，进入cmd 命令行，可以启动。<br><img src="http://upload-images.jianshu.io/upload_images/3698622-9b047f516b942438.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="Pyspark-安装"><a href="#Pyspark-安装" class="headerlink" title="Pyspark 安装"></a>Pyspark 安装</h2><p>要求在本机已经安装好Spark。此外python 3.6 版本不兼容Spark 1.6，使用时需要注意。<br>新增环境变量：PYTHONPATH<br>值为：%SPARK_HOME%\Python;%SPARK_HOME%\python\lib\py4j-0.9-src.zip</p>
<p>同时，在python 的配置的Lib\site-packages 中新增pyspark.pth 文件，内容为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\dev\spark1.6.3\python</span><br></pre></td></tr></table></figure></p>
<p>重启CMD ，输入pyspark 即可<br><img src="http://upload-images.jianshu.io/upload_images/3698622-791496f526c654d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h1 id="开发环境搭建"><a href="#开发环境搭建" class="headerlink" title="开发环境搭建"></a>开发环境搭建</h1><h2 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h2><p>搭建一个maven 工程即可pom.xml 如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;</span><br><span class="line">  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">  &lt;groupId&gt;com.ych&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;ychTestSpark4S&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line">  &lt;inceptionYear&gt;2008&lt;/inceptionYear&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;spark.version&gt;1.6.2&lt;/spark.version&gt;</span><br><span class="line">        &lt;scala.version&gt;2.10&lt;/scala.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">  &lt;repositories&gt;</span><br><span class="line">    &lt;repository&gt;</span><br><span class="line">      &lt;id&gt;scala-tools.org&lt;/id&gt;</span><br><span class="line">      &lt;name&gt;Scala-Tools Maven2 Repository&lt;/name&gt;</span><br><span class="line">      &lt;url&gt;http://scala-tools.org/repo-releases&lt;/url&gt;</span><br><span class="line">    &lt;/repository&gt;</span><br><span class="line">  &lt;/repositories&gt;</span><br><span class="line"></span><br><span class="line">  &lt;pluginRepositories&gt;</span><br><span class="line">    &lt;pluginRepository&gt;</span><br><span class="line">      &lt;id&gt;scala-tools.org&lt;/id&gt;</span><br><span class="line">      &lt;name&gt;Scala-Tools Maven2 Repository&lt;/name&gt;</span><br><span class="line">      &lt;url&gt;http://scala-tools.org/repo-releases&lt;/url&gt;</span><br><span class="line">    &lt;/pluginRepository&gt;</span><br><span class="line">  &lt;/pluginRepositories&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-core_$&#123;scala.version&#125;&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-streaming_$&#123;scala.version&#125;&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-sql_$&#123;scala.version&#125;&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-hive_$&#123;scala.version&#125;&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-mllib_$&#123;scala.version&#125;&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.avro&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;avro&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;1.7.7&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;4.4&lt;/version&gt;</span><br><span class="line">      &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.specs&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;specs&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;1.2.5&lt;/version&gt;</span><br><span class="line">      &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;com.databricks&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-csv_2.10&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;1.0.3&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">  &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">  &lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">      &lt;plugin&gt;</span><br><span class="line">        &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;</span><br><span class="line">        &lt;executions&gt;</span><br><span class="line">          &lt;execution&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">              &lt;goal&gt;compile&lt;/goal&gt;</span><br><span class="line">              &lt;goal&gt;testCompile&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">          &lt;/execution&gt;</span><br><span class="line">        &lt;/executions&gt;</span><br><span class="line">        &lt;configuration&gt;</span><br><span class="line">          &lt;scalaVersion&gt;$&#123;scala.version&#125;.6&lt;/scalaVersion&gt;</span><br><span class="line">          &lt;args&gt;</span><br><span class="line">            &lt;arg&gt;-target:jvm-1.5&lt;/arg&gt;</span><br><span class="line">          &lt;/args&gt;</span><br><span class="line">        &lt;/configuration&gt;</span><br><span class="line">      &lt;/plugin&gt;</span><br><span class="line">      &lt;plugin&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;maven-eclipse-plugin&lt;/artifactId&gt;</span><br><span class="line">        &lt;configuration&gt;</span><br><span class="line">          &lt;downloadSources&gt;true&lt;/downloadSources&gt;</span><br><span class="line">          &lt;buildcommands&gt;</span><br><span class="line">            &lt;buildcommand&gt;ch.epfl.lamp.sdt.core.scalabuilder&lt;/buildcommand&gt;</span><br><span class="line">          &lt;/buildcommands&gt;</span><br><span class="line">          &lt;additionalProjectnatures&gt;</span><br><span class="line">            &lt;projectnature&gt;ch.epfl.lamp.sdt.core.scalanature&lt;/projectnature&gt;</span><br><span class="line">          &lt;/additionalProjectnatures&gt;</span><br><span class="line">          &lt;classpathContainers&gt;</span><br><span class="line">            &lt;classpathContainer&gt;org.eclipse.jdt.launching.JRE_CONTAINER&lt;/classpathContainer&gt;</span><br><span class="line">            &lt;classpathContainer&gt;ch.epfl.lamp.sdt.launching.SCALA_CONTAINER&lt;/classpathContainer&gt;</span><br><span class="line">          &lt;/classpathContainers&gt;</span><br><span class="line">        &lt;/configuration&gt;</span><br><span class="line">      &lt;/plugin&gt;</span><br><span class="line">    &lt;/plugins&gt;</span><br><span class="line">  &lt;/build&gt;</span><br><span class="line">  &lt;reporting&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">      &lt;plugin&gt;</span><br><span class="line">        &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;</span><br><span class="line">        &lt;configuration&gt;</span><br><span class="line">          &lt;scalaVersion&gt;$&#123;scala.version&#125;&lt;/scalaVersion&gt;</span><br><span class="line">        &lt;/configuration&gt;</span><br><span class="line">      &lt;/plugin&gt;</span><br><span class="line">    &lt;/plugins&gt;</span><br><span class="line">  &lt;/reporting&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Java-开发环境"><a href="#Java-开发环境" class="headerlink" title="Java 开发环境"></a>Java 开发环境</h2><p>同Scala</p>
<h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p>设定好，需要使用的python 环境即可。<br>spyder 根据anaconda 设定的python 环境，选择对应的spyder 启动即可。<br>pycharm 如下配置：<br><img src="http://upload-images.jianshu.io/upload_images/3698622-8b4c2e09d180aee1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/12/07/note4learnspark/" itemprop="url">
                  Spark学习笔记汇总
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-12-07T23:50:59+08:00" content="2017-12-07">
              2017-12-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Spark 作为目前最火的技术栈<del>或许 大概 应该 maybe 没有之一了吧</del>，看上去很厉害，实际上也很厉害。。。<br><del>去年，有个东西还准备自己造轮子解决，后来耽搁了，上周一搜，已经有大神造好了轮子</del><br>本篇，作为自己学习Spark 的一个记录，不涉及Spark 的具体介绍，主要是一些学习思路和学习资料的整理，资源都来自网络及社区，侵删。</p>
<h1 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h1><h2 id="编程语言"><a href="#编程语言" class="headerlink" title="编程语言"></a>编程语言</h2><p>学习使用Spark，需要有一定的基础知识，在编程语言的方面，目前支持了Scala、Java、Python、R。个人建议是Scala 或 Java。</p>
<ul>
<li><p>Scala<br>Scala 作为Spark 的开发语言，简洁、优雅、语法丰富、支持lamba表达式，能够明显的提高开发效率，唯一的问题就是代码的可读性稍差<del>刚开始用Scala 写Spark 的时候，都用笔在纸上写出各个RDD之间的转化</del> 。此外，会java的程序员一抓一大把，会Scala的略少，可能有一个学习的过程。</p>
<p>   <strong>快学Scala</strong><br>  很不错的书   <del>恩，买了到现在还跟新的一样</del><br>  PDF <a href="https://pan.baidu.com/s/1dEQiSEX" target="_blank" rel="external">下载链接</a> 密码：l9ef，请支持正版</p>
<p>   <strong>为Java程序员编写的Scala的入门教程</strong><br>非常实用的教程<del>1个小时从入门到精通</del><br>该教程仅在对语言和其编译器进行简要介绍。目的读者是那些已经具有一定编程经验，而想尝试一下Scala语言的人们。要阅读该教程，应当具有基础的面向对象编程的概念，尤其是Java语言的。<br><a href="https://www.iteblog.com/archives/1325.html" target="_blank" rel="external">传送门</a></p>
<p><strong>Scala语言规范</strong><br>Scala语言定义和一些核心库模块的参考手册，可以当工具书查。<br><a href="http://www.scala-lang.org/docu/files/Scala%E8%AF%AD%E8%A8%80%E8%A7%84%E8%8C%83.pdf" target="_blank" rel="external">传送门</a></p>
<p> <strong>菜鸟教程</strong><br><a href="http://www.runoob.com/scala/scala-tutorial.html" target="_blank" rel="external">http://www.runoob.com/scala/scala-tutorial.html</a></p>
</li>
</ul>
<ul>
<li><p>Java<br><del>这个没啥好说的</del><br>真是初学者的话，网上随便搜个<a href="http://www.runoob.com/java/java-tutorial.html" target="_blank" rel="external">教程</a>，装好JDK和IDE，先写个hello world，再了解下面向对象的知识，然后看看多线程，差不多可以边看API边用着了。剩下就是左手<a href="https://www.baidu.com/" target="_blank" rel="external">Google</a> 右手<a href="https://stackoverflow.com/" target="_blank" rel="external">Stack Overflow</a>了。<br>参考书的话，推荐<a href="https://pan.baidu.com/s/1eSIpBpC" target="_blank" rel="external">Java 核心技术</a> 和 <a href="https://pan.baidu.com/s/1i5BxQoH" target="_blank" rel="external">Thinking In Java</a>  <del>这么经典的书，你不买套正版的，好意思说自己是程序员么</del></p>
</li>
<li><p>Python<br>胶水型语言，即用即贴。各种神奇的库，机器学习、数据分析方便的一比。工业用就差那么点了。</p>
<p>  <strong>廖雪峰的python教程</strong><br>廖雪峰老师的这个<a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">教程</a>作为入门足够了。剩下的，看着<a href="http://spark.apache.org/docs/latest/api/python/index.html" target="_blank" rel="external">Spark 的官方API</a>，自己搜吧。</p>
</li>
<li><p>R<br>如果你本身就是搞数据分析出身，用R习惯了，那也不用学什么了。<br>如果你本身不会R，上面三个还不够你学么！！！ </p>
</li>
</ul>
<h2 id="算法知识"><a href="#算法知识" class="headerlink" title="算法知识"></a>算法知识</h2><ul>
<li>机器学习<br>如果你要使用 Spark MLlib 的话，你需要一定的机器学习基础，至少得知道你用的算法是什么吧。<br>周志华老师的<a href="https://pan.baidu.com/s/1mhG1oeO" target="_blank" rel="external">机器学习</a><br>斯坦福大学公开课 <a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">机器学习课程</a><br>Mitchell 的<a href="https://pan.baidu.com/s/1dF94n4H" target="_blank" rel="external">机器学习</a></li>
</ul>
<ul>
<li>图论<br>如果要使用Graph X 的话，需要一些图论 和 图计算的基本知识。<br><a href="https://pan.baidu.com/s/1dEFtAz3" target="_blank" rel="external">图论及其应用</a></li>
</ul>
<h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><p>  使用Spark SQL 的话，你需要一些SQL 的基本知识。</p>
<h1 id="入门教程"><a href="#入门教程" class="headerlink" title="入门教程"></a>入门教程</h1><p>Spark 的教程方法很多，最实用的是去官网，看Quick Start。<br>其他的，网上也有很多，整理了几个个人觉得很棒的教程。</p>
<ul>
<li><p>Spark 入门实战<br><a href="http://blog.csdn.net/yirenboy/article/details/47291765" target="_blank" rel="external">Spark 入门实战系列</a> 这套教程从Spark 的生态圈介绍开始，涉及了基础的开发环境搭建，基本概念的介绍，以及Spark 组件的使用。理论结合实践，demo 代码（基于Scala）一应俱全。可谓入门的不二之选。</p>
</li>
<li><p>Spark快速大数据分析<br><a href="http://www.ituring.com.cn/book/1558" target="_blank" rel="external">Spark快速大数据分析</a>，这本书200页左右，介绍了Spark RDD 的基本操作，以及其余模块的基本使用，非常适合初学者。</p>
</li>
<li><p>IDE推荐<br><strong>首选</strong>是IDEA<br><strong>次选</strong>是Eclipse<br><del>当然，你可以用vim，没人拦着你</del><br><strong>此外</strong>还有一个方式，在已经搭建好Spark 环境的集群上，直接进入<a href="http://blog.csdn.net/yeruby/article/details/41043039" target="_blank" rel="external">Spark shell</a>，都不用编译工程，可谓方便快捷，在实验一些逻辑的时候，能提高不少效率<br><strong>还有</strong>Spark 的Master 设置为local 的时候，可以直接运行IDE看到结果，无需打包上传至服务器，使用spark-submit 的方式提交。验证代码逻辑可用。</p>
</li>
</ul>
<h1 id="进阶教程"><a href="#进阶教程" class="headerlink" title="进阶教程"></a>进阶教程</h1><ul>
<li><p>Spark 高级大数据分析<br><a href="http://www.ituring.com.cn/book/1668" target="_blank" rel="external">Spark 高级大数据分析</a>介绍了如何利用Spark进行大规模数据分析的若干模式，通过实例向讲述了怎样解决分析型问题。</p>
</li>
<li><p>Apache Spark 源码剖析<br><a href="https://www.amazon.cn/Apache-Spark%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-%E8%AE%B8%E9%B9%8F/dp/B00U0A9L3C/ref=sr_1_6?ie=UTF8&amp;qid=1426825361&amp;sr=8-6&amp;keywords=spark" target="_blank" rel="external">Apache Spark 源码剖析</a> 以Spark 1.02版本源码为切入点，着力于探寻Spark所要解决的主要问题及其解决办法，通过一系列精心设计的小实验来分析每一步背后的处理逻辑。</p>
</li>
</ul>
<ul>
<li><p>Spark 源码走读<br>该<a href="http://www.cnblogs.com/hseagle/p/3664933.html" target="_blank" rel="external">系列</a> 从Spark Job 的提交开始，进行Spark的源码走读。<br><del>恩 他就是上面那本书的作者</del></p>
</li>
<li><p>Spark SQL 源码分析<br>盛利大神 源码阅读的<a href="http://blog.csdn.net/oopsoom/article/details/38257749" target="_blank" rel="external">笔记</a></p>
</li>
<li><p>Spark Streaming 源码解析系列<br>来自 腾讯 广点通 技术团队出品的<a href="https://github.com/lw-lin/CoolplaySpark/tree/master/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97" target="_blank" rel="external">源码解析</a></p>
</li>
<li><p>Spark MLlib 源码阅读<br><a href="http://blog.csdn.net/column/details/14894.html" target="_blank" rel="external">这个</a> 按照MLlib 中的次序，进行介绍。</p>
</li>
<li><p>RDD paper<br>Spark 诞生地 UCB 的论文<a href="http://www.ece.eng.wayne.edu/~sjiang/ECE7650-winter-16/12-spark-questions.pdf" target="_blank" rel="external">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</a> 系统的阐述了RDD的设计初衷和基本架构，对深入理解Spark 有很大的帮助。<br>这是一篇<a href="http://blog.sciencenet.cn/blog-425672-520947.html" target="_blank" rel="external">中文翻译</a></p>
</li>
</ul>
<ul>
<li><p>API<br>在开发的过程中，没有什么比官方文档更好的老师了。自己在<a href="http://spark.apache.org/docs/latest/index.html" target="_blank" rel="external">官网</a>找对应版本的API即可。</p>
</li>
<li><p>源码<br>在github 上有Spark 的源码，个人感觉目前用的比较多的是1.6.3 和 2.1.0 两个版本。Spark 1.6 和 2.x 设计上确有一些地方有了改动，但是总体的实现思路，还是类似的，看源码的话，根据自己当下使用的版本，开始看吧。一些设计理念可以借助上文的源码走读加深理解。</p>
</li>
</ul>
<h1 id="一些站点"><a href="#一些站点" class="headerlink" title="一些站点"></a>一些站点</h1><ul>
<li><p><a href="http://spark.csdn.net/" target="_blank" rel="external">CSDN 专栏</a></p>
</li>
<li><p><a href="https://www.iteblog.com/archives/category/spark/" target="_blank" rel="external">过往记忆-Spark专栏</a><br><del>依稀记得，当时年少，懵懂无知，网还被墙，一遇问题，只能度娘，结果搜到的解决方法，大多来自过往记忆</del></p>
</li>
</ul>
<ul>
<li><p><a href="http://jerryshao.me/" target="_blank" rel="external">邵塞塞</a><br>早期Spark contributor之一</p>
</li>
<li><p><a href="https://amplab.cs.berkeley.edu/author/mzaharia" target="_blank" rel="external">Matei Zaharia</a><br>UCB 的大神</p>
</li>
<li><p><a href="https://databricks.com/blog" target="_blank" rel="external">databricks</a></p>
</li>
</ul>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/12/体道/" itemprop="url">
                  体道
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-12T21:39:16+08:00" content="2017-02-12">
              2017-02-12
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/一语/" itemprop="url" rel="index">
                    <span itemprop="name">一语</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>半年时间，断断续续，一本《老子·庄子》 跟着我从南京、南京来来回回了七八次。再加上surface中的一本《易经》、一本《唐诗选》。算来，阅读量竟如此匮乏。（好吧，如果把Spark 、Scala 这些都算上的话，其实也不少 科科）<br>然后，这次出差回来，忽然就打了鸡血，又又又又 列了个清单。乱七八糟定了些目标。找了些书，慢慢看。顺便提醒自己做个记录。</p>
<p>PS：借用河上公 的题，来给自己开个好头吧。</p>
<p>书单Re：<br>各学科领域入门书籍推荐<br><a href="http://www.guokr.com/blog/21940/" target="_blank" rel="external">http://www.guokr.com/blog/21940/</a><br>豆瓣9分以上小说，文学，历史，哲学，心理学，法学，经济学图书<br><a href="https://www.douban.com/doulist/1739529/?start=75&amp;sort=seq&amp;sub_type=" target="_blank" rel="external"> https://www.douban.com/doulist/1739529/?start=75&amp;sort=seq&amp;sub_type=</a></p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/06/TODO-List/" itemprop="url">
                  TODO-List
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-06T22:54:16+08:00" content="2016-12-06">
              2016-12-06
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>提前转正了，小开森一下。<br>然后发现之前太忙，学了很多东西，都没有总结，写个list，慢慢填坑吧。</p>
<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><ul>
<li>HBase 原理</li>
<li>RowKey 设计</li>
<li>建表，建分区表，删表</li>
<li>增、改、查（过滤器）</li>
<li>协处理器</li>
<li>shell 使用</li>
<li>FAQ</li>
</ul>
<p>#Spark</p>
<ul>
<li>SparkSQL、Hive On Spark、Parquet</li>
<li>DataSet、DataFrame、RDD</li>
<li>SparkMLlib</li>
<li>SparkML</li>
<li>GraphX</li>
</ul>
<p>#Kafka</p>
<ul>
<li>Producer</li>
<li>Consumer</li>
<li>多线程</li>
<li>高可用</li>
<li>分区</li>
</ul>
<p>#HDFS</p>
<p>#Hadoop</p>
<ul>
<li>Yarn</li>
<li>Zookeeper</li>
<li>Map</li>
</ul>
<p>#数据挖掘</p>
<p>#Storm</p>
<p>#Zookeeper</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/06/基于Spark的图计算框架-GraphX/" itemprop="url">
                  基于Spark的图计算框架-Grphx(转）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-06T22:43:33+08:00" content="2016-12-06">
              2016-12-06
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>原链接打不开了，做个N手转载，做个记录<br><a href="http://huxiao64.github.io/graphx" target="_blank" rel="external">http://huxiao64.github.io/graphx</a></p>
<p>这篇介绍，应该是GraphX 官方文档的一个翻译（用作示例的那两张图，不忍吐槽）<br>。。。。</p>
<p>别的事出差，这个就先这样搁浅了。。</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/12/06/Git-笔记/" itemprop="url">
                  Git笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-06T22:38:33+08:00" content="2016-12-06">
              2016-12-06
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/DevOps/" itemprop="url" rel="index">
                    <span itemprop="name">DevOps</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Git是非常好用的分布式版本管理系统，学习记录如下</p>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><p><a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html</a></p>
<h1 id="Git分支管理"><a href="#Git分支管理" class="headerlink" title="Git分支管理"></a>Git分支管理</h1><p><a href="http://www.ruanyifeng.com/blog/2012/07/git.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2012/07/git.html</a></p>
<p>文中提到的Master 和 Developer 两条线的思路，非常棒，但是在具体的实践中，需要根据项目来确定。<br>今天和发哥讨论的结果是，如果像我司一样，有独立的测试部门，需要不时的从Master取版本，做集成测试，那么 需要两条线，管理比较方便。<br>如果规模较小，可以考虑只用一个master 足够，每次打个tag就行，无需专人负责dev -&gt;mastert 的merge，况且这部分容易有坑。</p>
<h1 id="Git-使用规范"><a href="#Git-使用规范" class="headerlink" title="Git 使用规范"></a>Git 使用规范</h1><p><a href="http://www.ruanyifeng.com/blog/2015/08/git-use-process.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2015/08/git-use-process.html</a></p>
<p>在我们实际的 项目中，每次commit之前，需要先pull，解决好冲突之后，才能commit。<br>在我们使用Gerrit的过程中，会出现Merge Appending 的报错，原因是，submit了 1234 4次，且4依赖于前面的，前面任意一项submit未通过，那么submit 4的时候会出现找个错误。所以，有依赖关系的请谨慎。</p>
<p>需要详细了解的内容：<br>cherry pick<br>rebase<br>tag</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/Ruby.png"
               alt="喵十八" />
          <p class="site-author-name" itemprop="name">喵十八</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">23</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">50</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/1525632730" target="_blank" title="Weibo">
                  
                    <i class="fa fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/Yao544303" target="_blank" title="GitHub">
                  
                    <i class="fa fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="" target="_blank" title="Twitter">
                  
                    <i class="fa fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">喵十八</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  



  
  
  

  

  

</body>
</html>
